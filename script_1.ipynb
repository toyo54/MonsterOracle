{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:08:28.674585Z",
     "start_time": "2026-01-08T11:08:28.654999Z"
    }
   },
   "cell_type": "code",
   "source": "### Import:",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:08:28.707301Z",
     "start_time": "2026-01-08T11:08:28.675555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Caricamento del dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:08:28.796595Z",
     "start_time": "2026-01-08T11:08:28.708284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"./data/monsters.csv\")\n",
    "    print(\"‚úÖ Dataset caricato con successo.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Errore: File non trovato.\")\n",
    "    raise\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset caricato con successo.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### --- PULIZIA PRELIMINARE---\n",
    "Prima di creare sub_race, dobbiamo assicurarci che 'subtype' non contenga valori inutili come \"any race\".\n",
    "Se li contiene, li trasformiamo in NaN (Null), cos√¨ la logica successiva potr√† riempirli con il Type."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:08:28.833982Z",
     "start_time": "2026-01-08T11:08:28.798982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"--- Pulizia valori ambigui ---\")\n",
    "\n",
    "# Lista di termini che vogliamo considerare come \"Vuoti\"\n",
    "junk_terms = ['any race', 'any', 'varies']\n",
    "\n",
    "# Controlliamo la colonna subtype\n",
    "if 'subtype' in df.columns:\n",
    "    for term in junk_terms:\n",
    "        # Trova le righe dove subtype contiene il termine spazzatura (es. \"any race\")\n",
    "        mask = df['subtype'].astype(str).str.contains(term, case=False, na=False)\n",
    "        \n",
    "        count = mask.sum()\n",
    "        if count > 0:\n",
    "            # Sostituisci con NaN (valore nullo reale)\n",
    "            df.loc[mask, 'subtype'] = np.nan\n",
    "            print(f\"üßπ Trovati e rimossi {count} casi di '{term}' in subtype.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pulizia valori ambigui ---\n",
      "üßπ Trovati e rimossi 28 casi di 'any race' in subtype.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### --- LOGICA DI AGGREGAZIONE ---\n",
    "1. Prendo **group**.\n",
    "2. Se group manca, prendo **subtype** (ora pulito da \"any race\").\n",
    "3. Se mancano entrambi, prendo **type**."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:08:28.897567Z",
     "start_time": "2026-01-08T11:08:28.844023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Base: Group\n",
    "df['sub_race'] = df['group']\n",
    "\n",
    "# 2. Fill con Subtype (i NaN e gli ex-\"any race\" vengono riempiti qui o saltati)\n",
    "df['sub_race'] = df['sub_race'].fillna(df['subtype'])\n",
    "\n",
    "# 3. Fill con Type (Fallback finale)\n",
    "df['sub_race'] = df['sub_race'].fillna(df['type'])\n",
    "\n",
    "print(\"‚úÖ Colonna 'sub_race' creata correttamente.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Colonna 'sub_race' creata correttamente.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### --- RIMIZIONE COLONNE VECCHIE ---\n",
    "Ora rimuoviamo group, subtype e desc (se presente)."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:08:28.936562Z",
     "start_time": "2026-01-08T11:08:28.902720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_to_drop = ['group', 'subtype', 'desc']\n",
    "# Filtriamo solo quelle che esistono davvero per evitare errori\n",
    "existing_cols_to_drop = [c for c in cols_to_drop if c in df.columns]\n",
    "\n",
    "if existing_cols_to_drop:\n",
    "    df = df.drop(columns=existing_cols_to_drop)\n",
    "    print(f\"üóëÔ∏è Colonne rimosse: {existing_cols_to_drop}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Colonne rimosse: ['group', 'subtype', 'desc']\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### --- RIORDINAMENTO COLONNE ---\n",
    "Spostiamo 'sub_race' dopo 'type'."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:08:28.959893Z",
     "start_time": "2026-01-08T11:08:28.938571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols = df.columns.tolist()\n",
    "\n",
    "if 'sub_race' in cols and 'type' in cols:\n",
    "    cols.remove('sub_race')\n",
    "    type_index = cols.index('type')\n",
    "    cols.insert(type_index + 1, 'sub_race')\n",
    "    df = df[cols]\n",
    "    print(\"abc Ordine colonne sistemato.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc Ordine colonne sistemato.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### --- VERIFICA FINALE ---\n",
    "Controlliamo se esistono ancora \"any race\" nella nuova colonna."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:08:29.025054Z",
     "start_time": "2026-01-08T11:08:28.962199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_junk = df[df['sub_race'].astype(str).str.contains(\"any race\", case=False)]\n",
    "if len(test_junk) == 0:\n",
    "    print(\"‚ú® PERFETTO: Nessun 'any race' trovato in sub_race.\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è ATTENZIONE: Ci sono ancora {len(test_junk)} righe con 'any race'.\")\n",
    "    print(test_junk[['name', 'type', 'sub_race']].head())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ú® PERFETTO: Nessun 'any race' trovato in sub_race.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### --- RIORDINAMENTO COLONNE ---\n",
    "Spostiamo 'sub_race' dopo 'type'."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output_path = \"./data/monsters.csv\"\n",
    "try:\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nüíæ Salvataggio completato in: {output_path}\")\n",
    "except PermissionError:\n",
    "    print(\"‚ùå Errore: File aperto. Chiudilo e riprova.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
